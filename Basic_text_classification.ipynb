{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/keras/datasets/imdb.py:129: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/keras/datasets/imdb.py:130: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "data = keras.datasets.imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = data.load_data(num_words=88000)\n",
    "# print(train_data[0].length)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our keys similar to cloth type in fashion sets\n",
    "word_index = data.get_word_index()\n",
    "# print(word_index)\n",
    "# Creating our own dictionary based on this.\n",
    "word_index ={k:(v+3) for k, v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0      #This will be used for making the datasets of same lengths\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2       #Unknown word....\n",
    "word_index[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above is \"Word to int encoding\", we want \"Int to Word decoding\" based on working on neural network\n",
    "# Hence, a reverse dictionary is to be made.\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_review(text):\n",
    "    return \" \".join([reverse_word_index.get(i, \"?\") for i in text])\n",
    "# \"?\" will be replacing the value based on the key \"i\" that is our input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]\n",
      "<START> please give this one a miss br br kristy swanson and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite lacklustre so all you madison fans give this a miss\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])\n",
    "print(decode_review(test_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1   591   202    14    31     6   717    10    10 18142 10698     5\n",
      "     4   360     7     4   177  5760   394   354     4   123     9  1035\n",
      "  1035  1035    10    10    13    92   124    89   488  7944   100    28\n",
      "  1668    14    31    23    27  7479    29   220   468     8   124    14\n",
      "   286   170     8   157    46     5    27   239    16   179 15387    38\n",
      "    32    25  7944   451   202    14     6   717     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0]\n",
      "<START> please give this one a miss br br kristy swanson and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite lacklustre so all you madison fans give this a miss <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "250 250\n",
      "25000 25000\n"
     ]
    }
   ],
   "source": [
    "# Way of normalization to make the datasets of same lengths.\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value=word_index[\"<PAD>\"],\n",
    "                                                       padding=\"post\", maxlen=250)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data, value=word_index[\"<PAD>\"],\n",
    "                                                      padding=\"post\", maxlen=250)\n",
    "\n",
    "# Test\n",
    "print(test_data[0])\n",
    "print(decode_review(test_data[0]))\n",
    "print(len(test_data[0]),len(train_data[0]))\n",
    "print(len(test_data),len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# Model down here\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(88000,16))\n",
    "# Another way of adding layers instead of listing out inside the Sequential function.\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation=\"sigmoid\")) #To squish value in between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          1408000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,408,289\n",
      "Trainable params: 1,408,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Compiling data\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "15000/15000 [==============================] - 2s 133us/sample - loss: 0.6916 - acc: 0.6473 - val_loss: 0.6894 - val_acc: 0.7097\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - 1s 80us/sample - loss: 0.6854 - acc: 0.7509 - val_loss: 0.6814 - val_acc: 0.7493\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - 1s 81us/sample - loss: 0.6728 - acc: 0.7675 - val_loss: 0.6659 - val_acc: 0.7558\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - 1s 80us/sample - loss: 0.6504 - acc: 0.7891 - val_loss: 0.6409 - val_acc: 0.7500\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - 1s 81us/sample - loss: 0.6167 - acc: 0.8059 - val_loss: 0.6067 - val_acc: 0.7817\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - 1s 81us/sample - loss: 0.5733 - acc: 0.8233 - val_loss: 0.5666 - val_acc: 0.8072\n",
      "Epoch 7/40\n",
      "15000/15000 [==============================] - 1s 81us/sample - loss: 0.5242 - acc: 0.8421 - val_loss: 0.5235 - val_acc: 0.8175\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - 1s 81us/sample - loss: 0.4741 - acc: 0.8607 - val_loss: 0.4830 - val_acc: 0.8310\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - 1s 77us/sample - loss: 0.4264 - acc: 0.8767 - val_loss: 0.4459 - val_acc: 0.8431\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - 1s 75us/sample - loss: 0.3830 - acc: 0.8919 - val_loss: 0.4143 - val_acc: 0.8513\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - 1s 82us/sample - loss: 0.3448 - acc: 0.9010 - val_loss: 0.3877 - val_acc: 0.8599\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - 1s 84us/sample - loss: 0.3119 - acc: 0.9096 - val_loss: 0.3660 - val_acc: 0.8660\n",
      "Epoch 13/40\n",
      "15000/15000 [==============================] - 1s 82us/sample - loss: 0.2840 - acc: 0.9158 - val_loss: 0.3476 - val_acc: 0.8719\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - 1s 79us/sample - loss: 0.2590 - acc: 0.9239 - val_loss: 0.3332 - val_acc: 0.8743\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - 1s 80us/sample - loss: 0.2376 - acc: 0.9308 - val_loss: 0.3224 - val_acc: 0.8769\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - 1s 80us/sample - loss: 0.2185 - acc: 0.9368 - val_loss: 0.3121 - val_acc: 0.8778\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - 1s 79us/sample - loss: 0.2011 - acc: 0.9431 - val_loss: 0.3044 - val_acc: 0.8821\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - 1s 79us/sample - loss: 0.1857 - acc: 0.9480 - val_loss: 0.2975 - val_acc: 0.8826\n",
      "Epoch 19/40\n",
      "15000/15000 [==============================] - 1s 82us/sample - loss: 0.1718 - acc: 0.9530 - val_loss: 0.2919 - val_acc: 0.8850\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - 1s 81us/sample - loss: 0.1595 - acc: 0.9578 - val_loss: 0.2879 - val_acc: 0.8846\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - 1s 81us/sample - loss: 0.1476 - acc: 0.9613 - val_loss: 0.2839 - val_acc: 0.8864\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - 1s 81us/sample - loss: 0.1370 - acc: 0.9651 - val_loss: 0.2818 - val_acc: 0.8865\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - 1s 81us/sample - loss: 0.1263 - acc: 0.9687 - val_loss: 0.2806 - val_acc: 0.8871\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - 1s 81us/sample - loss: 0.1171 - acc: 0.9715 - val_loss: 0.2775 - val_acc: 0.8864\n",
      "Epoch 25/40\n",
      "15000/15000 [==============================] - 1s 82us/sample - loss: 0.1084 - acc: 0.9746 - val_loss: 0.2768 - val_acc: 0.8870\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - 1s 80us/sample - loss: 0.1005 - acc: 0.9781 - val_loss: 0.2776 - val_acc: 0.8865\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - 1s 81us/sample - loss: 0.0934 - acc: 0.9801 - val_loss: 0.2770 - val_acc: 0.8876\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - 1s 80us/sample - loss: 0.0868 - acc: 0.9819 - val_loss: 0.2766 - val_acc: 0.8884\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - 1s 80us/sample - loss: 0.0810 - acc: 0.9845 - val_loss: 0.2809 - val_acc: 0.8883\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - 1s 82us/sample - loss: 0.0758 - acc: 0.9852 - val_loss: 0.2787 - val_acc: 0.8886\n",
      "Epoch 31/40\n",
      "15000/15000 [==============================] - 1s 85us/sample - loss: 0.0702 - acc: 0.9867 - val_loss: 0.2798 - val_acc: 0.8885\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - 1s 83us/sample - loss: 0.0656 - acc: 0.9880 - val_loss: 0.2816 - val_acc: 0.8897\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - 1s 79us/sample - loss: 0.0612 - acc: 0.9890 - val_loss: 0.2833 - val_acc: 0.8879\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - 1s 80us/sample - loss: 0.0573 - acc: 0.9901 - val_loss: 0.2851 - val_acc: 0.8879\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - 1s 82us/sample - loss: 0.0541 - acc: 0.9905 - val_loss: 0.2878 - val_acc: 0.8878\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - 1s 84us/sample - loss: 0.0503 - acc: 0.9920 - val_loss: 0.2899 - val_acc: 0.8875\n",
      "Epoch 37/40\n",
      "15000/15000 [==============================] - 1s 81us/sample - loss: 0.0471 - acc: 0.9927 - val_loss: 0.2923 - val_acc: 0.8873\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - 1s 81us/sample - loss: 0.0442 - acc: 0.9936 - val_loss: 0.2964 - val_acc: 0.8870\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - 1s 82us/sample - loss: 0.0419 - acc: 0.9939 - val_loss: 0.2965 - val_acc: 0.8873\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - 1s 83us/sample - loss: 0.0389 - acc: 0.9942 - val_loss: 0.3001 - val_acc: 0.8867\n"
     ]
    }
   ],
   "source": [
    "# Dividing data into training and validating data, which keeps checking val_data to get more accuracy or patterns\n",
    "# inside the dataset.\n",
    "x_val =train_data[:10000]\n",
    "x_train =train_data[10000:]\n",
    "\n",
    "y_val =train_labels[:10000]\n",
    "y_train =train_labels[10000:]\n",
    "\n",
    "# Fitting Model\n",
    "fitModel= model.fit(x_train, y_train, epochs=40, batch_size=512, validation_data=(x_val, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 33us/sample - loss: 0.3333 - acc: 0.8727\n",
      "[0.3332644413995743, 0.87272]\n"
     ]
    }
   ],
   "source": [
    "results =model.evaluate(test_data, test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: \n",
      "<START> please give this one a miss br br kristy swanson and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite lacklustre so all you madison fans give this a miss <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "Prediction: [0.]\n",
      "Actual: 0\n"
     ]
    }
   ],
   "source": [
    "test_review = test_data[0]\n",
    "predict = model.predict([test_review])\n",
    "print(\"Review: \")\n",
    "print(decode_review(test_review))\n",
    "print(\"\\nPrediction: \"+str(predict[0]))\n",
    "print(\"Actual: \"+str(test_labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "print(len(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"MovieReview.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'review_encode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0615e3719975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mnline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\")\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"()\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mreview_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         encode =keras.preprocessing.sequence.pad_sequences([encode], value=word_index[\"<PAD>\"],\n\u001b[1;32m      6\u001b[0m                                                        padding=\"post\", maxlen=250)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'review_encode' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"Review.txt\", encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        nline = line.replace(\",\",\"\").replace(\".\",\"\").replace(\")\",\"\").replace(\"()\",\"\").replace(\":\",\"\").replace(\"\\\"\",\"\").split(\" \")\n",
    "        encode =review_encode(nline)\n",
    "        encode =keras.preprocessing.sequence.pad_sequences([encode], value=word_index[\"<PAD>\"],\n",
    "                                                       padding=\"post\", maxlen=250)\n",
    "        predict=model.predict(encode)\n",
    "        print(line)\n",
    "        print(encode)\n",
    "        print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
